# core/converter.py
# Version: v3.6.1_Final_Lite
# Last Updated: 2026-01-06
# Description: ç§»é™¤æ‰€æœ‰å†—ä½™çš„ETAæ—¶é—´è®¡ç®—ä»£ç ï¼›ä¿ç•™å¯†åº¦æ£€æµ‹ï¼›ä»…ä¸“æ³¨äºè½¬æ¢æ ¸å¿ƒé€»è¾‘ã€‚

import os
import time
import tempfile
import shutil
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
from weasyprint import HTML, CSS
from weasyprint.text.fonts import FontConfiguration

from config import LARGE_FILE_THRESHOLD_MB, APP_VERSION
from utils.helpers import sanitize_filename
from core.merger import PDFMergerEngine


class ConverterEngine:
    def __init__(self, epub_path, output_path, settings, callback_manager):
        self.epub_path = os.path.abspath(epub_path)
        self.output_path = os.path.abspath(output_path)
        self.settings = settings
        self.cb = callback_manager
        self.image_manifest = {}
        self.stop_flag = False

    # =========================================================================
    # [v3.5.1] å¯†åº¦æ£€æµ‹ç®—æ³• (ä¿ç•™)
    # æ ¸å¿ƒé€»è¾‘ï¼šè®¡ç®—â€œå¹³å‡æ¯ä¸ªç‰©ç†æ–‡ä»¶åŒ…å«å¤šå°‘ä¸ªç« èŠ‚â€ã€‚
    # =========================================================================
    @staticmethod
    def analyze_structure(epub_path):
        try:
            book = epub.read_epub(epub_path, options={'ignore_ncx': False})
            toc_count = len(book.toc)

            unique_files = set()
            for node in book.toc:
                href = ""
                if isinstance(node, tuple):
                    if hasattr(node[0], 'href'): href = node[0].href
                elif hasattr(node, 'href'):
                    href = node.href
                if href: unique_files.add(href.split('#')[0])

            file_count = len(unique_files)
            if file_count == 0: file_count = 1

            density = toc_count / file_count
            is_monolithic = (density > 5.0) or (toc_count > 50 and file_count < 5)

            report = (
                f"ğŸ“Š ç»“æ„æ·±åº¦åˆ†æ:\n"
                f"â€¢ é€»è¾‘ç« èŠ‚: {toc_count} | ç‰©ç†æ–‡ä»¶: {file_count}\n"
                f"â€¢ å†…å®¹å¯†åº¦: {density:.2f} (é˜ˆå€¼: 5.0)\n"
                f"â€¢ åˆ¤å®šç»“æœ: {'âš ï¸ ç»“æ„è‡ƒè‚¿/å•ä½“' if is_monolithic else 'âœ… ç»“æ„è§„èŒƒ/æ•£åˆ—'}"
            )
            return is_monolithic, report
        except Exception as e:
            return False, f"åˆ†æå¤±è´¥: {str(e)}"

    def stop(self):
        self.stop_flag = True
        self.cb.log("ğŸ›‘ æ­£åœ¨å“åº”åœæ­¢æŒ‡ä»¤...")

    def _check_stop(self):
        if self.stop_flag: raise InterruptedError("ç”¨æˆ·æ‰‹åŠ¨ä¸­æ­¢")

    def run(self):
        # start_time ä»…ç”¨äºæœ€ç»ˆæ—¥å¿—çš„ç®€è¦è€—æ—¶è®°å½•ï¼Œä¸å‚ä¸é€»è¾‘æ§åˆ¶
        start_time = time.time()
        self.stop_flag = False
        try:
            file_size = os.path.getsize(self.epub_path) / (1024 * 1024)
            mode = self.settings.get('mode', 'auto')

            self.cb.log(f"å¼€å§‹ä»»åŠ¡: {os.path.basename(self.epub_path)}")
            self._check_stop()

            is_split_mode = False
            if mode == 'split':
                is_split_mode = True
            elif mode == 'single':
                is_split_mode = False
            else:
                is_split_mode = (file_size >= LARGE_FILE_THRESHOLD_MB)

            success = False
            result_msg = ""
            final_path = ""
            cleanup_path = None

            if is_split_mode:
                self.cb.log(">>> æ‰§è¡Œæ ‡å‡†åˆ†å·é€»è¾‘...")
                success, files, folder = self.convert_split_mode()

                if success and self.settings.get('auto_merge', True):
                    self._check_stop()
                    self.cb.log("æ­£åœ¨æ‰§è¡Œåˆå¹¶...")
                    merger = PDFMergerEngine()
                    merge_out = os.path.join(os.path.dirname(self.epub_path),
                                             f"{os.path.splitext(os.path.basename(self.epub_path))[0]}_å…¨æœ¬.pdf")
                    # åˆå¹¶è¿›åº¦æ¡
                    ok, path = merger.merge(files, merge_out,
                                            lambda c, t, m: self.cb.update_progress(90 + int(c / t * 10), m))
                    if ok:
                        result_msg = "åˆ†å·åŠåˆå¹¶å®Œæˆ"
                        final_path = path
                        cleanup_path = folder
                    else:
                        result_msg = "åˆ†å·å®Œæˆï¼Œåˆå¹¶å¤±è´¥"
                        final_path = folder
                else:
                    result_msg = "åˆ†å·å·²ç”Ÿæˆ"
                    final_path = folder
            else:
                self.cb.log(">>> æ‰§è¡Œå•æ–‡ä»¶é€»è¾‘...")
                success, msg = self.convert_single_mode()
                result_msg = msg
                final_path = self.output_path

            duration = int(time.time() - start_time)
            m, s = divmod(duration, 60)
            return success, result_msg, f"{m}åˆ†{s}ç§’", final_path, cleanup_path

        except InterruptedError:
            return False, "ä»»åŠ¡ä¸­æ­¢", "0åˆ†0ç§’", "", None
        except Exception as e:
            return False, str(e), "0åˆ†0ç§’", "", None

    # === å•æ–‡ä»¶æ¨¡å¼ ===
    def convert_single_mode(self):
        try:
            # è¿™é‡Œçš„ start_t ä»…ç”¨äºæ§åˆ¶å°å¾®è§‚æ—¥å¿—ï¼Œä¸å½±å“æ ¸å¿ƒ
            start_t = time.time()
            self.cb.update_progress(10, "è¯»å– EPUB...")
            book = epub.read_epub(self.epub_path)
            self._check_stop()

            with tempfile.TemporaryDirectory() as temp_dir:
                self.cb.update_progress(20, "è§£å‹èµ„æº...")
                self._extract_images_and_build_manifest(book, temp_dir)

                full_html = []
                cover_html = self._get_cover_html(book, temp_dir)
                if cover_html: full_html.append(cover_html)

                self.cb.update_progress(30, "è§£æç« èŠ‚...")
                total = len(book.spine)
                for i, item_id in enumerate(book.spine):
                    self._check_stop()
                    item = book.get_item_with_id(item_id[0])
                    if item:
                        c = self._clean_and_fix_html(item, temp_dir)
                        if c: full_html.append(c)
                    if i % 10 == 0:
                        elapsed = int(time.time() - start_t)
                        self.cb.update_progress(30 + int(i / total * 30), f"è§£æä¸­ {i}/{total}")

                self.cb.log("ç”Ÿæˆæ’ç‰ˆ (CSS)...")
                final_html = f"<html><body>{''.join(full_html)}</body></html>"
                font_config = FontConfiguration()
                css = CSS(string=self._generate_css(), font_config=font_config)

                self.cb.update_progress(70, "æ¸²æŸ“ PDF (WeasyPrint)...")
                html = HTML(string=final_html, base_url=temp_dir)

                self._check_stop()
                self.cb.log("å†™å…¥ç£ç›˜ (IO)...")
                html.write_pdf(self.output_path, stylesheets=[css], font_config=font_config)

            return True, f"è½¬æ¢æˆåŠŸ"
        except Exception as e:
            raise e

    # === åˆ†å·æ¨¡å¼ (v3.6.1 æè‡´ç²¾ç®€ç‰ˆ) ===
    # åˆ é™¤äº†æ‰€æœ‰ ETA è®¡ç®—ä»£ç ï¼Œè¿›åº¦æ¡åªæ˜¾ç¤ºå¤„ç†å¯¹è±¡
    def convert_split_mode(self):
        try:
            epub_dir = os.path.dirname(self.epub_path)
            folder_name = os.path.splitext(os.path.basename(self.epub_path))[0] + "_åˆ†å·"
            target_dir = os.path.join(epub_dir, folder_name)
            if not os.path.exists(target_dir): os.makedirs(target_dir)

            book = epub.read_epub(self.epub_path)
            if not book.toc: return False, [], None

            generated = []

            with tempfile.TemporaryDirectory() as temp_dir:
                self._extract_images_and_build_manifest(book, temp_dir)
                font_config = FontConfiguration()
                css = CSS(string=self._generate_css(), font_config=font_config)

                total = len(book.toc)
                for idx, node in enumerate(book.toc):
                    self._check_stop()

                    # [ç²¾ç®€] ç§»é™¤æ‰€æœ‰æ—¶é—´è®¡ç®—ï¼Œåªä¿ç•™è¿›åº¦ç™¾åˆ†æ¯”å’Œæ ‡é¢˜
                    title = node.title if hasattr(node, 'title') else node[0].title
                    safe_title = sanitize_filename(title)
                    self.cb.update_progress(int((idx / total) * 90), f"å¤„ç†: {safe_title}")

                    hrefs = self._find_all_hrefs(node)
                    chapter_html = []
                    seen = set()
                    for href in hrefs:
                        parts = href.split('#');
                        fname = parts[0];
                        anchor = parts[1] if len(parts) > 1 else None
                        if fname in seen and not anchor: continue
                        seen.add(fname)
                        item = book.get_item_with_href(fname)
                        if item:
                            c = self._clean_and_fix_html(item, temp_dir, anchor_id=anchor)
                            if c: chapter_html.append(c)

                    if chapter_html:
                        out = os.path.join(target_dir, f"{idx + 1:02d}_{safe_title}.pdf")
                        HTML(string=f"<html><body>{''.join(chapter_html)}</body></html>", base_url=temp_dir).write_pdf(
                            out, stylesheets=[css], font_config=font_config)
                        generated.append(out)

            return True, generated, target_dir
        except Exception as e:
            raise e

    # === è¾…åŠ©å·¥å…· ===
    def _extract_images_and_build_manifest(self, b, t):
        self.image_manifest = {}
        for i in b.get_items():
            self._check_stop()
            if i.get_type() == ebooklib.ITEM_IMAGE:
                path = os.path.join(t, i.get_name())
                os.makedirs(os.path.dirname(path), exist_ok=True)
                with open(path, 'wb') as f: f.write(i.get_content())
                self.image_manifest[os.path.basename(i.get_name())] = path

    def _clean_and_fix_html(self, item, temp_dir, anchor_id=None):
        if not item: return None
        soup = BeautifulSoup(item.get_content(), 'html.parser')
        for img in soup.find_all('img'):
            src = img.get('src')
            if src:
                fname = os.path.basename(src)
                if fname in self.image_manifest: img[
                    'src'] = f"file:///{self.image_manifest[fname].replace(os.sep, '/')}"
        return soup.find('body').decode_contents() if soup.find('body') else None

    def _find_all_hrefs(self, node):
        hrefs = []
        if isinstance(node, tuple):
            sec, children = node
            if hasattr(sec, 'href'): hrefs.append(sec.href)
            for c in children: hrefs.extend(self._find_all_hrefs(c))
        elif hasattr(node, 'href'):
            hrefs.append(node.href)
        return hrefs

    def _get_cover_html(self, b, t):
        return ""

    def _generate_css(self):
        s = self.settings
        return f"""@page {{ size: {s['paper']}; margin: {s['margin_tb']}mm {s['margin_lr']}mm; @bottom-center {{ content: counter(page); font-family: serif; font-size: 10pt; }} }} body {{ font-family: "SimSun", "Microsoft YaHei"; font-size: {s['font_size']}pt; line-height: 1.6; text-align: justify; }} img {{ max-width: 100%; }}"""